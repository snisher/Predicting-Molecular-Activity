{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PMB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHSLI-S31cf-",
        "colab_type": "text"
      },
      "source": [
        "#Predicting Molecular Bioactivity\n",
        "\n",
        "Fisher Moritzburke (fmoritzb) & \n",
        "Martin Hoffmann (maedhoff)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Y9tk7V1Y-H",
        "colab_type": "code",
        "outputId": "255c58a5-d245-4140-96d4-ebbcc4ed77e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split # split into training/test\n",
        "from sklearn import preprocessing  # for standardizing the data\n",
        "from sklearn import metrics  # Useful for creating confusion matrices\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "Activation = keras.layers.Activation\n",
        "to_categorical = keras.utils.to_categorical\n",
        "Sequential = keras.Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.layers.merge import add\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvIfRaF9116d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = [\n",
        "    ('HIVINT', '18wUy7Ax3LcpbOWEWxnd6vZ2q7K6Bd9IA'), #15.3MB\n",
        "    ('HIVPROT', '1kQZWm-Nxf5M-do_LwNabPEfMpdVKmLxZ'), #37.1MB\n",
        "    #('TDI', '1QAM7yM4pnN8_cLsTkccMhZZxFr8f9xRQ'), #47.8MB\n",
        "    ('OX1', '15bNN3_eyKlgGLOqN-veLgNLRqFAdU64P'), #49.5MB\n",
        "    ('THROMBIN', '11RJO5lG-pd1a_GrtraXx811wfkJHG-16'), #53.6MB\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qICV0CCv1-sX",
        "colab_type": "text"
      },
      "source": [
        "#Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2fHAdho2Ckb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes a (int or float) and returns a boolean\n",
        "def greater_than_zero(val):\n",
        "  # returns True if the value is greater than 0\n",
        "  assert isinstance(val, (int, float))\n",
        "  return(True if val>0 else False)\n",
        "\n",
        "# takes a pandas dataframe and an int, returns a pandas dataframe\n",
        "def drop_irrelevant_columns(data, n):\n",
        "  # drops columns from the dataframe with less than n non-zero values\n",
        "  num_columns = len(data.columns)\n",
        "  to_drop = []\n",
        "  for col in data.columns[2:]:\n",
        "    if list(map(greater_than_zero, data[col])).count(True) < n:\n",
        "      to_drop.append(col)\n",
        "\n",
        "  data = data.drop(columns=to_drop)\n",
        "  \n",
        "  remaining_percentage = round( ((len(data.columns)-2)/num_columns)*100, 2)\n",
        "  print(f'{len(to_drop)} columns have been dropped. {len(data.columns)} columns ({remaining_percentage}%) remain.')\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gDdEDuF5GxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes a (int or float) and returns a (int or float)\n",
        "def log(val):\n",
        "  if not isinstance(val, (int, float)):\n",
        "    return val\n",
        "  if val == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return math.log(val+1, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfhS43JO2FdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# r_square accuracy metric function\n",
        "def r_square(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fn6-xsY2J7p",
        "colab_type": "text"
      },
      "source": [
        "#Build and evaluate models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgk_g9Dy2H4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(dataset_name, dataset_file_id, min_molecules_per_column = -1,\n",
        "           log_transform=True, \n",
        "           nn_epochs=150,\n",
        "           autoencoder_epochs=50,\n",
        "           nn_ae_epochs=150,\n",
        "           resMLP_epochs=200,\n",
        "           verbose=2):\n",
        "  print(f\"{dataset_name} data set...\")\n",
        "  \n",
        "  histories = {}\n",
        "  \n",
        "  Dropout = keras.layers.Dropout\n",
        "  Dense = keras.layers.Dense\n",
        "  \n",
        "  # 1) fetch data from google drive\n",
        "  link = 'https://drive.google.com/uc?export=download&id={FILE_ID}'\n",
        "  csv_url = link.format(FILE_ID = dataset_file_id)\n",
        "  try:\n",
        "    data = pd.read_csv(csv_url, sep=',')\n",
        "  except Exception as e:\n",
        "    print('There was an error parsing the csv file!')\n",
        "    return\n",
        "  \n",
        "  # 2) remove irrelevant columns:\n",
        "  if min_molecules_per_column > -1:\n",
        "    data = drop_irrelevant_columns(data, min_molecules_per_column)\n",
        "    \n",
        "  # 3) apply a logarithmic transformation:\n",
        "  if log_transform:\n",
        "    data = data.applymap(log)\n",
        "  \n",
        "  # 4) split the dataset in training and test data:\n",
        "  cols = data.columns.tolist()[2:]    # exclude MOLECULE and Act\n",
        "  X = data[cols]\n",
        "  y = data['Act']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
        "  \n",
        "  # make sure data is numpy array\n",
        "  if isinstance(X_train, pd.DataFrame):\n",
        "    X_train = X_train.values\n",
        "    X_test = X_test.values\n",
        "  \n",
        "  # 5) build, train, & evaluate the models\n",
        "  \n",
        "  #============ Standard MLP ===============#\n",
        "  \n",
        "  model = Sequential()\n",
        "\n",
        "  input_dim = X_train.shape[1]\n",
        "\n",
        "  # Add layers\n",
        "  model.add( Dense(2000, activation='relu', input_dim = input_dim))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(1000, activation='relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(1000, activation='relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(1000, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  # Layer 5, output layer\n",
        "  model.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "  # Compile the NN model, defining the optimizer to use, the loss function, and the metrics to use.\n",
        "  model.compile(optimizer = 'RMSprop',\n",
        "               loss = 'mse',\n",
        "               metrics = [r_square])\n",
        "  \n",
        "  # fit the model to the training data:\n",
        "  print('training the MLP...')\n",
        "  history = model.fit(X_train, \n",
        "    y_train,\n",
        "    validation_split = 0.2, \n",
        "    epochs = nn_epochs, \n",
        "    batch_size = 50,\n",
        "    verbose = verbose,\n",
        "  )\n",
        "  \n",
        "  # Evaluate the MLP's performance\n",
        "  evaluation = {}\n",
        "  \n",
        "  train_loss, train_acc = model.evaluate(X_train, y_train) # evaluate\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test) # evaluate\n",
        "  \n",
        "  evaluation['train_acc'] = train_acc\n",
        "  evaluation['test_acc'] = test_acc\n",
        "  evaluation['train_loss'] = train_loss\n",
        "  evaluation['test_loss'] = test_loss\n",
        "  \n",
        "  print('MLP test set accuracy:', test_acc, '\\n')\n",
        "  \n",
        "  histories['MLP'] = {'history': history.history,\n",
        "                      'evaluation' : evaluation}\n",
        "  \n",
        "  \n",
        "  #============ Encoder + MLP ===============#\n",
        "  \n",
        "  # create the autoencoder:\n",
        "  input_dim = X_train.shape[1] # the input size\n",
        "  encoding_dim = 50 # the size of the encoded representation\n",
        "  compression_factor = float(input_dim) / encoding_dim\n",
        "\n",
        "  autoencoder = Sequential() # create sequential model\n",
        "  # Encoder Layers\n",
        "  autoencoder.add(Dense(input_dim/4, input_shape=(input_dim,), activation='relu'))\n",
        "  autoencoder.add(Dense(input_dim/10, activation='relu'))\n",
        "  autoencoder.add(Dense(encoding_dim, activation='relu')) # encoded state\n",
        "  # Decoding Layers\n",
        "  autoencoder.add(Dense(input_dim/10, activation='relu'))\n",
        "  autoencoder.add(Dense(input_dim/4, activation='relu'))\n",
        "  autoencoder.add(Dense(input_dim, activation='relu'))\n",
        "\n",
        "  autoencoder.compile(optimizer='RMSprop',\n",
        "    loss = 'mse', metrics=[r_square])\n",
        "\n",
        "  autoencoder_history = autoencoder.fit(X_train, X_train,\n",
        "    epochs=autoencoder_epochs, #50\n",
        "    batch_size=256,\n",
        "    validation_data=(X_test, X_test),\n",
        "    verbose = verbose,\n",
        "  )\n",
        "  \n",
        "  \n",
        "  # build a new model using the autoencoder as a basis:\n",
        "  ae_model = Sequential()\n",
        "\n",
        "  # Fist add the encoding layers trained previously\n",
        "  ae_model.add(autoencoder.layers[0])\n",
        "  ae_model.add(autoencoder.layers[1])\n",
        "  ae_model.add(autoencoder.layers[2])\n",
        "\n",
        "  # add an additional 2 FC layers\n",
        "  ae_model.add(Dense(50, activation='relu'))\n",
        "  ae_model.add(Dropout(0.25))\n",
        "  ae_model.add(Dense(20, activation='relu'))\n",
        "  ae_model.add(Dropout(0.1))\n",
        "  # output layer\n",
        "  ae_model.add(Dense(1, activation = 'linear'))\n",
        "  \n",
        "  ae_model.compile(optimizer = 'RMSprop',\n",
        "             loss = 'mse',\n",
        "             metrics = [r_square])\n",
        "\n",
        "  print('Training the encoder + MLP...')\n",
        "  \n",
        "  history = ae_model.fit(X_train, \n",
        "    y_train,\n",
        "    validation_split = 0.33, \n",
        "    epochs = nn_ae_epochs, #300 \n",
        "    batch_size = 32,\n",
        "    verbose = verbose,\n",
        "  )\n",
        "  \n",
        "  # Evaluate the model's performance\n",
        "  evaluation = {}\n",
        "  \n",
        "  train_loss, train_acc = ae_model.evaluate(X_train, y_train) # evaluate\n",
        "  test_loss, test_acc = ae_model.evaluate(X_test, y_test) # evaluate\n",
        "  \n",
        "  evaluation['train_acc'] = train_acc\n",
        "  evaluation['test_acc'] = test_acc\n",
        "  evaluation['train_loss'] = train_loss\n",
        "  evaluation['test_loss'] = test_loss\n",
        "\n",
        "  print('encoder + MLP test set accuracy:', test_acc, '\\n')\n",
        "  \n",
        "  histories['ae_MLP'] = {'history': history.history, \n",
        "                         'evaluation': evaluation}\n",
        "  \n",
        "  #============ residual MLP ===============# \n",
        "  from keras.layers import Input, Dense, Dropout\n",
        "  \n",
        "  # residualBlock layer. Returns the outputs and the new size of the tensor\n",
        "  def residualBlock(inputs, size):\n",
        "    outputs = Dense(size, activation='relu')(inputs) # Dense relu\n",
        "    outputs = Dropout(.2)(outputs) # dropout\n",
        "    outputs = add([outputs, inputs]) # add layers\n",
        "    outputs = Dense(size//2, activation='relu')(outputs)\n",
        "    return outputs, size//2\n",
        "  \n",
        "  inSize = X_train.shape[1] # size of input\n",
        "  \n",
        "  visible = Input(shape=(inSize,), name='input') # input layer\n",
        "  x, size = residualBlock(visible, inSize)\n",
        "  x, size = residualBlock(x, size)\n",
        "  x, size = residualBlock(x, size)\n",
        "  x, size = residualBlock(x, size)\n",
        "  x, size = residualBlock(x, size)\n",
        "  x, size = residualBlock(x, size)\n",
        "  x, size = residualBlock(x, size)\n",
        "  x, size = residualBlock(x, size)\n",
        "  output = Dense(1, activation='linear')(x)\n",
        "  \n",
        "  resMLP = Model(inputs=visible, outputs=output)\n",
        "  \n",
        "  resMLP.compile(optimizer = 'RMSprop',\n",
        "                loss = 'mse',\n",
        "                metrics = [r_square])\n",
        "  \n",
        "  print('Training the resMLP...')\n",
        "  \n",
        "  history = resMLP.fit(X_train, \n",
        "                      y_train,\n",
        "                      validation_split = 0.2, \n",
        "                      epochs = resMLP_epochs,\n",
        "                      batch_size = 100,\n",
        "                      verbose = verbose)\n",
        "  \n",
        "  # Evaluate the model's performance\n",
        "  evaluation = {}\n",
        "  train_loss, train_acc = resMLP.evaluate(X_train, y_train) # evaluate train\n",
        "  test_loss, test_acc = resMLP.evaluate(X_test, y_test) # evaluate test\n",
        "  # save evaluations\n",
        "  evaluation['train_acc'] = train_acc\n",
        "  evaluation['test_acc'] = test_acc\n",
        "  evaluation['train_loss'] = train_loss\n",
        "  evaluation['test_loss'] = test_loss\n",
        "  \n",
        "  print('residual MLP test set accuracy:', test_acc)\n",
        "  \n",
        "  histories['resMLP'] = {'history': history.history,\n",
        "                         'evaluation': evaluation}\n",
        "\n",
        "  print('\\n')\n",
        "  \n",
        "  return histories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PXg_waL2N1s",
        "colab_type": "code",
        "outputId": "5c67a51d-89e1-45f1-ba61-3e1265e0f5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Building models')\n",
        "results = {}\n",
        "\n",
        "for dataset in datasets:\n",
        "  name = dataset[0]\n",
        "\n",
        "  results[name] = run(\n",
        "    dataset_name             = name, \n",
        "    dataset_file_id          = dataset[1],\n",
        "    min_molecules_per_column = 30,\n",
        "    log_transform            = True,\n",
        "    nn_epochs=150, \n",
        "    autoencoder_epochs=50,\n",
        "    nn_ae_epochs=200,\n",
        "    resMLP_epochs=200, \n",
        "    verbose=0\n",
        "  )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO72P4en2ivx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print evaluation for each dataset\n",
        "for dataset in results.keys():\n",
        "  print('Dataset:', dataset)\n",
        "  print('  MLP - test accuracy', '=', results[dataset]['MLP']['evaluation']['test_acc'])\n",
        "  print('  Encoder+MLP - test accuracy', '=', results[dataset]['ae_MLP']['evaluation']['test_acc'])\n",
        "  print('  Residual MLP - test accuracy', '=', results[dataset]['resMLP']['evaluation']['test_acc'])\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSp6deeV6zCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
